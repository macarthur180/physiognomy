import cv2
import dlib
import numpy as np
import joblib
import os

# ëª¨ë¸ íŒŒì¼ ë¡œë“œ
model_path = "/home/nano/project/eye_model.pkl"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
label_encoder_path = "/home/nano/project/label_encoder.pkl"  # ì €ì¥ëœ ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("/home/nano/project/shape_predictor_68_face_landmarks.dat")

# ì €ì¥ëœ ì‚¬ì§„ í´ë” ê²½ë¡œ
pic_dir = "/home/nano/project/pic/"

# ê°€ì¥ ìµœê·¼ ì´¬ì˜ëœ ì‚¬ì§„ ì°¾ê¸°
def get_latest_image(directory):
    files = [f for f in os.listdir(directory) if f.endswith(('.jpg', '.png'))]
    if not files:
        print("âŒ ì €ì¥ëœ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤.")
        exit()
    latest_file = max(files, key=lambda x: os.path.getctime(os.path.join(directory, x)))
    return os.path.join(directory, latest_file)

latest_image = get_latest_image(pic_dir)
print(f"ğŸ” ë¶„ì„í•  ì‚¬ì§„: {latest_image}")

# ì´ë¯¸ì§€ ë¡œë“œ
img = cv2.imread(latest_image)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# ì–¼êµ´ ê²€ì¶œ
faces = detector(gray)
if len(faces) == 0:
    print("âŒ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

for face in faces:
    landmarks = predictor(gray, face)

    # ì–¼êµ´ í¬ê¸°
    face_width = face.right() - face.left()
    face_height = face.bottom() - face.top()

    # ì™¼ìª½ ëˆˆ (36~41)
    left_eye_x = [landmarks.part(n).x for n in range(36, 42)]
    left_eye_y = [landmarks.part(n).y for n in range(36, 42)]
    left_eye_width = max(left_eye_x) - min(left_eye_x)
    left_eye_height = max(left_eye_y) - min(left_eye_y)

    # ì˜¤ë¥¸ìª½ ëˆˆ (42~47)
    right_eye_x = [landmarks.part(n).x for n in range(42, 48)]
    right_eye_y = [landmarks.part(n).y for n in range(42, 48)]
    right_eye_width = max(right_eye_x) - min(right_eye_x)
    right_eye_height = max(right_eye_y) - min(right_eye_y)

    # ëˆˆ ì‚¬ì´ ê±°ë¦¬ (39ë²ˆê³¼ 42ë²ˆ ì‚¬ì´ ê±°ë¦¬)
    eye_distance = np.linalg.norm(
        np.array([landmarks.part(39).x, landmarks.part(39).y]) - 
        np.array([landmarks.part(42).x, landmarks.part(42).y])
    )

    # ëˆˆê¼¬ë¦¬ ê¸°ìš¸ê¸° (39ë²ˆê³¼ 42ë²ˆ ì‚¬ì´ ê¸°ìš¸ê¸°)
    eye_angle = np.arctan2(landmarks.part(42).y - landmarks.part(39).y, 
                            landmarks.part(42).x - landmarks.part(39).x) * 180 / np.pi

    # ë¹„ìœ¨ ê³„ì‚°
    left_eye_ratio = left_eye_width / face_width
    right_eye_ratio = right_eye_width / face_width
    eye_distance_ratio = eye_distance / face_width
    eye_height_ratio = (left_eye_height + right_eye_height) / (2 * face_height)

    # ëª¨ë¸ ë° ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ
    model = joblib.load(model_path)
    label_encoder = joblib.load(label_encoder_path)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    features = np.array([[left_eye_ratio, right_eye_ratio, eye_distance_ratio, eye_height_ratio, eye_angle]])
    prediction = model.predict(features)

    # ìˆ«ìë¥¼ ì›ë˜ ëˆˆ ìœ í˜•ìœ¼ë¡œ ë³€í™˜
    predicted_eye_type = label_encoder.inverse_transform(prediction)

    print(f"ğŸ”® ì˜ˆì¸¡ëœ ëˆˆ ìœ í˜•: {predicted_eye_type[0]}")  # ì˜ˆì¸¡ëœ ê´€ìƒ ìœ í˜• ì¶œë ¥
